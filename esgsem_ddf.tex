%% This is based on bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/
\documentclass[conference,a4paper]{IEEEtran}

\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage[cmex10]{amsmath}
\usepackage{fixltx2e}
\usepackage{url}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Dynamic Dataflow}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Risto Vuorio}
%\IEEEauthorblockA{Your Association}
}

% make the title area
\maketitle

\begin{abstract}
Dynamic dataflow is a model of computation that is well suited for the
construction of parallel programs. In dynamic dataflow the program logic is
divided into actors that can execute in any order depending only on the data
availability. In most dynamic dataflow implementations the actors are stateless,
which results in a model of computation that resembles functional programming in
many respects. 

As the need for high performance parallel computing is growing, dynamic dataflow
based frameworks such as TensorFlow have been introduced to make programming
parallel programs easier. In this paper an introduction to the dynamic dataflow
model of computation is given, the motivation for adoption of the model for
parallel computing is explained and example implementations of the model are
explored.
\end{abstract}

\section{Introduction}
A program following the dataflow model of computation (MoC) consists of a
directed graph with data flowing between the nodes. The data is split into
tokens that are passed between the nodes. The execution of the nodes is
asynchronous. Due to the asynchronous execution the tokens have to be buffered
between the nodes. The dataflow MoC allows for unbounded execution of the model,
which means the dataflow program may execute for a very long time. The
possibility of unbounded execution leads to the problems the different dataflow
MoCs try to solve. A dataflow program capable of unbounded execution 1. may have
unbounded buffer growth 2. if there are cycles, the execution may result in a
deadlock where there are not enough tokens to advance the execution. A good
introduction on the dataflow MoCs is given in \cite{lee2015introduction}.

One popular approach to solving these problems is the synchronous dataflow
(SDF). In SDF the number of tokens produced and consumed by each actor is fixed.
The SDF MoC guarantees bounded buffers and deadlock-free execution but it is
very constrained. For expressing more complicated programs, models with more
design freedom are needed. \cite{lee2015introduction}

There exists a variety of Dataflow MoCs that extend the concept of synchronous
dataflow such as the parameterized and interfaced synchronous dataflow (PiSDF)
\cite{desnos2013pimm}, which extends SDF expressive power by defining parameters
and interfaces. The resulting PiSDF model can be expressed as a SDF. We will not
look at these extensions of SDF but at the more generic Dataflow MoCs
categorized under dynamic dataflow. Dynamic dataflow does not refer to a single
MoC but is rather an umbrella term under which many MoCs fall.

\section{Dynamic Dataflow}
In Dynamic Dataflow (DDF) the number of tokens consumed or produced by an actor
in a single firing is not constrained. An actor can produce and consume
different number of tokens in every firing. This freedom improves the expression
power of the model but makes the analysis more difficult. The difficulty is
underlined by the fact that for the most general class of dataflow models that
bounded buffers and deadlocks are not decidable as proved by Buck
\cite{buck1993scheduling}. It is possible to define dynamic dataflow models that
are decidable by introducing limitations on the types of actors and graph
patterns that can be used in the model \cite{bhattacharyya2013handbook,
gao1992well}. However these limitations are most often traded for the increased
expressive power of the models without such limitations
\cite{bhattacharyya2013handbook}.

Bhattacharyya et al. \cite{bhattacharyya2013handbook} describe many examples of
DDF MoCs. One of these examples is the CAL Actor Language (CAL). CAL is used for
example by the MPEG Reconfigurable Video Coding library. Another example use of
dynamic dataflow is in the TensorFlow (TF) machine learning library by Google
\cite{tensorflow2015-whitepaper}. TF programs are structured as DDF graphs. The
computations in the nodes can be distributed to heterogeneous computing devices
such as CPUs and GPUs. TF provides control flow operators that can be added to
the graph to support conditional execution of parts of the graph and loops.

Dynamic dataflow is a useful model of computation for handling streaming data.
Signal processing applications typically deal with streaming data in the form of
audio, video or other kinds of streams. Streaming data can also be other types
of numeric data, as in the TensorFlow framework, or even textual data as is
often processed in web analytics. The successive and independent dataflow actors
provide logical division of computation for stream processing. The stream
processing context is encountered in the practical use of DDF MoCs
\cite{eker2003cal, tensorflow2015-whitepaper} and in the research where most of
the studies are focused on the performance of either video or audio stream
applications \cite{bhattacharyya2013handbook, roquier2008automatic,
ersfolk2014scheduling}.

Although some of the practical implementations of dynamic dataflow
\cite{tensorflow2015-whitepaper, eker2003cal} allow stateful actors, most of the
dynamic dataflow MoCs presented in \cite{bhattacharyya2013handbook} do not
implement stateful actors to help the analysis of the models. The division of
computation to stateless and independent blocks resembles functional programming
to some extent. This similarity between functional programming and dataflow
models of computation is explored in \cite{reekie1995realtime}.

\subsection{Common Features of DDF Models}
look at HSPS12 here \\
explain switch / select / graph iterations \\

\subsection{Example problems solved using DDF}
HSPS12 has MPEG4 and MP3 decoder examples \\
Stream Computation \\

\subsection{TensorFlow}
Motivation for DDF in TF \\
Explain how DDF is implemented in TF \\

\section{Conclusion}
Conclude \\

%\begin{figure}[!t]
%\centering
%\includegraphics[width=21pc]{Aalto_EN_SCI_21_RGB_y2.pdf}
%\caption{An example 1-column figure. You can also include PNG-files
%  directly. Use, \emph{e.g.}, \texttt{convert} to convert images from
%  other formats. The image width is 21 pc.}
%\label{fig:example-1col}
%\end{figure}
%
%\begin{figure*}[t]
%\centering
%\includegraphics[width=43pc]{Aalto_EN_SCI_13_RGB_b1.pdf}
%\caption{An example 2-column figure. The image is in embedded PDF
%  vector format which is the best graphics format for print. The image
%  width is 43 pc.}
%\label{fig:example-2col}
%\end{figure*}

\bibliographystyle{IEEEtran}
\bibliography{papers}

\end{document}

